import streamlit as st
import pandas as pd
import os
import sys
import json
from typing import Dict, List, Optional
from streamlit_option_menu import option_menu

# Proje kÃ¶k dizinini sisteme tanÄ±tarak diÄŸer modÃ¼lleri import et
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from src.vector_db.embedding_service import AgentEmbeddingService
from src.rag.rag_pipeline import RAGPipeline
from src.evaluation.evaluator import AgentEvaluator, EvaluationMetrics

# --- Sayfa YapÄ±landÄ±rmasÄ± ---
st.set_page_config(
    page_title="AI Agent DeÄŸerlendirme Paneli",
    page_icon="ğŸ¤–",
    layout="wide"
)

st.title("ğŸ¤– AI Agent DeÄŸerlendirme Paneli")
st.markdown("""
Bu panel, kaydedilmiÅŸ ajan konuÅŸmalarÄ±nÄ± analiz etmek ve ajanlarÄ±n performansÄ±nÄ± `Agent Goal'Ä±na Uygun DavranmÄ±ÅŸ mÄ±?` belgesindeki kriterlere gÃ¶re deÄŸerlendirmek iÃ§in tasarlanmÄ±ÅŸtÄ±r.
""")

# --- Servisleri BaÅŸlatma ---
@st.cache_resource
def initialize_services() -> Optional[AgentEvaluator]:
    """Gerekli servisleri baÅŸlatÄ±r ve Ã¶nbelleÄŸe alÄ±r."""
    try:
        project_root = "src"
        db_path = os.path.join(project_root, "chroma_db_openai")
        
        embedding_service = AgentEmbeddingService(persist_directory=db_path)
        # Not: RAG Pipeline'Ä± tam olarak kullanmÄ±yoruz, Ã§Ã¼nkÃ¼ baÄŸlam sohbet geÃ§miÅŸinden geliyor.
        # Ancak deÄŸerlendirici iÃ§in bir RAG context'i simÃ¼le etmemiz gerekebilir.
        # rag_pipeline = RAGPipeline(embedding_service=embedding_service) 
        evaluator = AgentEvaluator()
        return evaluator
    except Exception as e:
        st.error(f"Servisler baÅŸlatÄ±lÄ±rken bir hata oluÅŸtu: {e}")
        return None

evaluator = initialize_services()

# --- Veri Ä°ÅŸleme FonksiyonlarÄ± ---
@st.cache_data
def process_chat_data(chats_df: pd.DataFrame, personas_df: pd.DataFrame, tasks_df: pd.DataFrame) -> pd.DataFrame:
    """Sohbet verilerini iÅŸleyip soru-cevap Ã§iftleri haline getirir."""
    # Ã‡akÄ±ÅŸmayÄ± Ã¶nlemek iÃ§in 'created_at' sÃ¼tunlarÄ±nÄ± birleÅŸtirmeden Ã¶nce yeniden adlandÄ±r
    personas_df.rename(columns={'created_at': 'persona_created_at'}, inplace=True)
    tasks_df.rename(columns={'created_at': 'task_created_at'}, inplace=True)
    
    personas_df = personas_df.sort_values('persona_created_at').drop_duplicates('agent_id', keep='last')
    tasks_df = tasks_df.sort_values('task_created_at').drop_duplicates('agent_id', keep='last')
    
    merged_df = pd.merge(chats_df, personas_df, on='agent_id', how='left')
    merged_df = pd.merge(merged_df, tasks_df, on='agent_id', how='left')
    
    user_chats = merged_df[merged_df['type'] == 'USER'].rename(columns={'content': 'user_query', 'created_at': 'user_time'})
    assistant_chats = merged_df[merged_df['type'] == 'ASSISTANT'].rename(columns={'content': 'agent_response', 'created_at': 'assistant_time'})
    
    user_chats['chat_rank'] = user_chats.groupby('chat_id').cumcount()
    assistant_chats['chat_rank'] = assistant_chats.groupby('chat_id').cumcount()
    
    qa_df = pd.merge(
        user_chats[user_chats['chat_rank'] == 0], 
        assistant_chats[assistant_chats['chat_rank'] > 0],
        on=['chat_id', 'agent_id'],
        suffixes=('_user', '_assistant')
    )
    
    # HATA DÃœZELTMESÄ°: BirleÅŸtirme sonrasÄ± _user ve _assistant olarak ayrÄ±lan sÃ¼tunlarÄ± dÃ¼zelt
    if 'persona_user' in qa_df.columns:
        qa_df['persona'] = qa_df['persona_user']
    if 'tasks_user' in qa_df.columns:
        qa_df['tasks'] = qa_df['tasks_user']

    qa_df = qa_df.sort_values('assistant_time').drop_duplicates('chat_id', keep='first')
    return qa_df.dropna(subset=['user_query', 'agent_response', 'persona', 'tasks'])

@st.cache_data
def load_default_data(data_path: str) -> pd.DataFrame:
    """VarsayÄ±lan veri dosyalarÄ±nÄ± yÃ¼kler ve iÅŸler."""
    try:
        chats_df = pd.read_csv(os.path.join(data_path, "ai_agent_chat_messages_june_18_25.csv"))
        personas_df = pd.read_csv(os.path.join(data_path, "ai_agent_persona_june_18_25.csv"))
        tasks_df = pd.read_csv(os.path.join(data_path, "ai_agent_tasks_june_18_25.csv"))
        return process_chat_data(chats_df, personas_df, tasks_df)
    except FileNotFoundError as e:
        st.error(f"Veri dosyasÄ± bulunamadÄ±: {e.filename}")
        return pd.DataFrame()

# --- DeÄŸerlendirme Fonksiyonu ---
def run_evaluation(eval_data: pd.Series, _evaluator: AgentEvaluator) -> Optional[EvaluationMetrics]:
    """Tek bir konuÅŸma verisi iÃ§in deÄŸerlendirmeyi Ã§alÄ±ÅŸtÄ±rÄ±r."""
    try:
        user_query = str(eval_data['user_query'])
        agent_response = str(eval_data['agent_response'])
        agent_persona = str(eval_data['persona'])
        
        try:
            tasks_str = str(eval_data.get('tasks', '[]'))
            tasks = json.loads(tasks_str.replace("'", "\""))
            task_descriptions = [t.get('value', {}).get('about', '') for t in tasks if t.get('type') == 'talk-about']
            agent_goal = ". ".join(filter(None, task_descriptions)) or "KullanÄ±cÄ±ya yardÄ±mcÄ± olmak."
        except (json.JSONDecodeError, TypeError):
            agent_goal = "KullanÄ±cÄ±ya yardÄ±mcÄ± olmak."
        
        rag_context = f"Agent'Ä±n bilgi tabanÄ±ndan getirdiÄŸi varsayÄ±lan kanÄ±t: '{agent_response}'"

        return _evaluator.evaluate_conversation(
            user_query=user_query, agent_response=agent_response,
            agent_goal=agent_goal, rag_context=rag_context,
            agent_persona=agent_persona, tool_calls=None
        )
    except Exception as e:
        st.error(f"DeÄŸerlendirme hatasÄ±: {e}")
        return None

def display_evaluation_results(evaluation_result: Optional[EvaluationMetrics]):
    """DeÄŸerlendirme sonuÃ§larÄ±nÄ± gÃ¶rselleÅŸtirir."""
    if not evaluation_result:
        st.error("DeÄŸerlendirme sonucu alÄ±namadÄ±.")
        return
        
    st.header("ğŸ“Š DeÄŸerlendirme SonuÃ§larÄ±")
    cols = st.columns(4)
    metrics_to_show = {
        "Goal Adherence": evaluation_result.goal_adherence,
        "Answer Relevance": evaluation_result.answer_relevance,
        "Groundedness": evaluation_result.groundedness,
        "Persona Compliance": getattr(evaluation_result, 'persona_compliance', None),
        "Style & Courtesy": getattr(evaluation_result, 'style_and_courtesy', None),
        "Conciseness": getattr(evaluation_result, 'conciseness', None),
        "Knowledge Boundary": evaluation_result.knowledge_boundary_violation,
        "Security/Policy": evaluation_result.security_policy_violation,
    }
    
    col_idx = 0
    for name, metric in metrics_to_show.items():
        if metric is None: continue
        with cols[col_idx % 4]:
            delta_color = "inverse" if name in ["Knowledge Boundary", "Security/Policy"] and metric.score > 0 else "normal"
            st.metric(label=name, value=f"{metric.score:.2f}", delta_color=delta_color)
            with st.expander("GerekÃ§eyi GÃ¶r"):
                st.write(metric.reasoning)
        col_idx += 1

@st.cache_data
def load_and_merge_raw_data(data_path: str) -> pd.DataFrame:
    """VarsayÄ±lan veri dosyalarÄ±nÄ± yÃ¼kler ve birleÅŸtirir, ancak QA formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼rmez."""
    try:
        chats_df = pd.read_csv(os.path.join(data_path, "ai_agent_chat_messages_june_18_25.csv"))
        personas_df = pd.read_csv(os.path.join(data_path, "ai_agent_persona_june_18_25.csv"))
        tasks_df = pd.read_csv(os.path.join(data_path, "ai_agent_tasks_june_18_25.csv"))
        
        personas_df.rename(columns={'created_at': 'persona_created_at'}, inplace=True)
        tasks_df.rename(columns={'created_at': 'task_created_at'}, inplace=True)
    
        personas_df = personas_df.sort_values('persona_created_at').drop_duplicates('agent_id', keep='last')
        tasks_df = tasks_df.sort_values('task_created_at').drop_duplicates('agent_id', keep='last')
        
        merged_df = pd.merge(chats_df, personas_df, on='agent_id', how='left')
        merged_df = pd.merge(merged_df, tasks_df, on='agent_id', how='left')
        
        return merged_df.dropna(subset=['content', 'persona', 'tasks'])
    except FileNotFoundError as e:
        st.error(f"Veri dosyasÄ± bulunamadÄ±: {e.filename}")
        return pd.DataFrame()

def run_session_evaluation(session_df: pd.DataFrame, _evaluator: AgentEvaluator) -> Optional[EvaluationMetrics]:
    """TÃ¼m bir oturumu deÄŸerlendirir."""
    try:
        full_conversation = []
        for _, row in session_df.sort_values('created_at').iterrows():
            full_conversation.append({"role": str(row['type']).lower(), "content": str(row['content'])})
        
        agent_persona = session_df['persona'].iloc[0]
        try:
            tasks_str = str(session_df['tasks'].iloc[0])
            tasks = json.loads(tasks_str.replace("'", "\""))
            task_descriptions = [t.get('value', {}).get('about', '') for t in tasks if t.get('type') == 'talk-about']
            agent_goal = ". ".join(filter(None, task_descriptions)) or "KullanÄ±cÄ±ya yardÄ±mcÄ± olmak."
        except (json.JSONDecodeError, TypeError):
            agent_goal = "KullanÄ±cÄ±ya yardÄ±mcÄ± olmak."

        return _evaluator.evaluate_session(full_conversation, agent_goal, str(agent_persona))
    except Exception as e:
        st.error(f"Oturum deÄŸerlendirme hatasÄ±: {e}")
        return None

# --- NAVÄ°GASYON ---
with st.sidebar:
    # Projeyi taÅŸÄ±nabilir hale getirmek iÃ§in yerel ve gÃ¶receli bir yol kullanÄ±n.
    # 'use_column_width' genellikle daha iyi kalite iÃ§in geniÅŸliÄŸi optimize eder.
    st.image("src/assets/Jotform-New-Logo.png", use_container_width='auto')
    st.title("AI Agent DeÄŸerlendirme")
    
    page = option_menu(
        menu_title=None,
        options=["Sandbox", "Toplu DeÄŸerlendirme", "Oturum Analizi"],
        icons=["beaker", "collection-fill", "chat-left-text-fill"],
        menu_icon="cast",
        default_index=0,
    )

# --- Sayfa 1: Manuel DeÄŸerlendirme (Sandbox) ---
if page == "Sandbox":
    st.header("ğŸ§ª Manuel DeÄŸerlendirme (Sandbox)")
    st.markdown("""
    Bu bÃ¶lÃ¼mde, belirlediÄŸiniz bir senaryoya gÃ¶re ajanÄ±n potansiyel performansÄ±nÄ± deÄŸerlendirebilirsiniz. 
    AÅŸaÄŸÄ±daki alanlarÄ± doldurarak varsayÄ±msal bir durumu test edin.
    """)

    with st.form(key="sandbox_form"):
        user_query = st.text_area("ğŸ‘¤ KullanÄ±cÄ± Sorusu", height=100, placeholder="Ã–r: Jotform'un sunduÄŸu farklÄ± abonelik planlarÄ± nelerdir?")
        agent_response = st.text_area("ğŸ¤– AjanÄ±n CevabÄ±", height=150, placeholder="Ã–r: Elbette, Jotform'da Ãœcretsiz, Bronz, GÃ¼mÃ¼ÅŸ ve AltÄ±n olmak Ã¼zere dÃ¶rt farklÄ± plan bulunmaktadÄ±r. Her planÄ±n form limiti, gÃ¶nderi sayÄ±sÄ± ve depolama alanÄ± gibi farklÄ± Ã¶zellikleri vardÄ±r. Ä°htiyaÃ§larÄ±nÄ±za en uygun olanÄ± seÃ§menize yardÄ±mcÄ± olabilirim.")
        agent_persona = st.text_area("ğŸ­ Ajan PersonasÄ±", height=150, value="YardÄ±msever, profesyonel ve Ã§Ã¶zÃ¼m odaklÄ± bir asistansÄ±nÄ±z. KullanÄ±cÄ±nÄ±n sorununu net bir ÅŸekilde anlayÄ±p etkili bir Ã§Ã¶zÃ¼m sunmaya odaklanmalÄ±sÄ±nÄ±z.")
        agent_goal = st.text_area("ğŸ¯ AjanÄ±n GÃ¶revi (Goal)", height=100, value="KullanÄ±cÄ±nÄ±n Jotform hakkÄ±ndaki sorularÄ±nÄ± yanÄ±tlamak ve onlara platformu en verimli ÅŸekilde nasÄ±l kullanacaklarÄ± konusunda rehberlik etmek.")
        
        submit_button = st.form_submit_button(label="ğŸ§ª Senaryoyu DeÄŸerlendir", use_container_width=True, type="primary")

    if submit_button:
        if not all([user_query, agent_response, agent_persona, agent_goal]):
            st.warning("LÃ¼tfen deÄŸerlendirme yapmadan Ã¶nce tÃ¼m alanlarÄ± doldurun.")
        elif evaluator:
            with st.spinner("Senaryo deÄŸerlendiriliyor..."):
                rag_context = f"Agent'Ä±n bilgi tabanÄ±ndan getirdiÄŸi varsayÄ±lan kanÄ±t: '{agent_response}'"
                
                result = evaluator.evaluate_conversation(
                    user_query=user_query,
                    agent_response=agent_response,
                    agent_goal=agent_goal,
                    rag_context=rag_context,
                    agent_persona=agent_persona,
                    tool_calls=None
                )
                display_evaluation_results(result)
        else:
            st.error("DeÄŸerlendirici servisi (Evaluator) baÅŸlatÄ±lamadÄ±.")

# --- Sayfa 2: Toplu DeÄŸerlendirme ---
elif page == "Toplu DeÄŸerlendirme":
    st.header("ğŸ“š Dosya YÃ¼kleyerek Toplu DeÄŸerlendirme")
    st.markdown("""
    Sohbet geÃ§miÅŸini iÃ§eren bir `.csv` dosyasÄ± yÃ¼kleyerek tÃ¼m konuÅŸmalarÄ± otomatik olarak deÄŸerlendirin.
    **Not:** YÃ¼kleyeceÄŸiniz dosyanÄ±n, `ai_agent_chat_messages_june_18_25.csv` ile aynÄ± formatta olmasÄ± beklenmektedir.
    """)

    uploaded_file = st.file_uploader("Sohbet (.csv) dosyasÄ±nÄ± seÃ§in", type="csv")

    if uploaded_file is not None:
        try:
            # YÃ¼klenen dosyadan bir DataFrame oluÅŸtur
            uploaded_chats_df = pd.read_csv(uploaded_file)
            st.success(f"`{uploaded_file.name}` dosyasÄ± baÅŸarÄ±yla yÃ¼klendi ve {len(uploaded_chats_df)} satÄ±r okundu.")
            
            # Bu ajanlarÄ±n persona ve task verilerini de varsayÄ±lan dosyalardan alalÄ±m
            data_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), "data")
            personas_df = pd.read_csv(os.path.join(data_path, "ai_agent_persona_june_18_25.csv"))
            tasks_df = pd.read_csv(os.path.join(data_path, "ai_agent_tasks_june_18_25.csv"))

            batch_data = process_chat_data(uploaded_chats_df, personas_df, tasks_df)

            if st.button(f"ğŸ“š {len(batch_data)} KonuÅŸmayÄ± Toplu DeÄŸerlendir", key="eval_batch", use_container_width=True, type="primary"):
                if evaluator and not batch_data.empty:
                    results = []
                    progress_bar = st.progress(0, text="DeÄŸerlendirme baÅŸladÄ±...")
                    
                    for i, (_, row) in enumerate(batch_data.iterrows()):
                        result = run_evaluation(row, evaluator)
                        if result:
                            results.append(result.model_dump())
                        progress_bar.progress((i + 1) / len(batch_data), text=f"KonuÅŸma {i+1}/{len(batch_data)} deÄŸerlendiriliyor...")
                    
                    progress_bar.empty()
                    st.success("Toplu deÄŸerlendirme tamamlandÄ±!")

                    results_df = pd.DataFrame(results)
                    
                    # SonuÃ§larÄ± metrik sÃ¼tunlarÄ±na ayÄ±r
                    for metric in ["goal_adherence", "answer_relevance", "groundedness", "persona_compliance", "style_and_courtesy", "conciseness", "knowledge_boundary_violation", "security_policy_violation"]:
                        if metric in results_df.columns:
                            results_df[f'{metric}_score'] = results_df[metric].apply(lambda x: x['score'] if isinstance(x, dict) else None)
                            results_df[f'{metric}_reasoning'] = results_df[metric].apply(lambda x: x['reasoning'] if isinstance(x, dict) else None)

                    # Genel istatistikleri gÃ¶ster
                    st.subheader("Genel Metrikler")
                    avg_cols = st.columns(4)
                    avg_cols[0].metric("Toplam KonuÅŸma", len(results_df))
                    avg_cols[1].metric("Ort. Groundedness", f"{results_df['groundedness_score'].mean():.2f}")
                    avg_cols[2].metric("Ort. Relevance", f"{results_df['answer_relevance_score'].mean():.2f}")
                    avg_cols[3].metric("Ort. Style", f"{results_df['style_and_courtesy_score'].mean():.2f}")


                    # DetaylÄ± sonuÃ§larÄ± gÃ¶ster
                    with st.expander("TÃ¼m DeÄŸerlendirme SonuÃ§larÄ±nÄ± GÃ¶r"):
                        display_cols = ['chat_id', 'user_query', 'agent_response', 'goal_adherence_score', 'groundedness_score', 'answer_relevance_score']
                        # Orijinal veriden sÃ¼tunlarÄ± ekle
                        display_df = batch_data[['chat_id', 'user_query', 'agent_response']].reset_index(drop=True)
                        scores_df = results_df[[col for col in results_df.columns if '_score' in col]].reset_index(drop=True)
                        full_display_df = pd.concat([display_df, scores_df], axis=1)
                        
                        st.dataframe(full_display_df)

                elif batch_data.empty:
                    st.warning("YÃ¼klenen dosyadan iÅŸlenecek geÃ§erli bir konuÅŸma bulunamadÄ±.")
                else:
                    st.error("DeÄŸerlendirici servisi (Evaluator) baÅŸlatÄ±lamadÄ±.")

        except Exception as e:
            st.error(f"Dosya iÅŸlenirken bir hata oluÅŸtu: {e}") 

# --- Sayfa 3: Oturum DeÄŸerlendirme ---
elif page == "Oturum Analizi":
    st.header("ğŸ’¬ Sohbet Oturumu SeÃ§imi ve Analizi")
    data_path = "src/data"
    session_raw_data = load_and_merge_raw_data(data_path)

    if not session_raw_data.empty:
        chat_ids = session_raw_data['chat_id'].unique()
        
        # KullanÄ±cÄ± yeni bir oturum seÃ§tiÄŸinde eski sonuÃ§larÄ± temizlemek iÃ§in bir callback
        def on_chat_id_change():
            if 'session_eval_result' in st.session_state:
                del st.session_state['session_eval_result']

        selected_chat_id = st.selectbox(
            "DeÄŸerlendirilecek Oturumu SeÃ§in (Chat ID):", 
            chat_ids,
            key="chat_id_selector",
            on_change=on_chat_id_change
        )

        if selected_chat_id:
            session_df = session_raw_data[session_raw_data['chat_id'] == selected_chat_id].copy()
            
            st.subheader(f"Oturum DÃ¶kÃ¼mÃ¼: `{selected_chat_id}`")
            with st.container(height=400):
                for _, row in session_df.sort_values('created_at').iterrows():
                    user_type = str(row.get('type', 'assistant')).upper()
                    with st.chat_message(name="user" if user_type == 'USER' else "assistant"):
                        st.markdown(str(row.get('content', '')))
            
            with st.expander("Agent GÃ¶rev ve Persona DetaylarÄ±"):
                if not session_df.empty and 'persona' in session_df.columns:
                    st.code(str(session_df['persona'].iloc[0]), language=None)

            if st.button("ğŸš€ Bu Oturumu DeÄŸerlendir", key="eval_session", use_container_width=True, type="primary"):
                if evaluator and not session_df.empty:
                    with st.spinner("Oturum deÄŸerlendiriliyor..."):
                        result = run_session_evaluation(session_df, evaluator)
                        # DeÄŸerlendirme sonucunu session_state'e kaydet
                        st.session_state['session_eval_result'] = result
                elif session_df.empty:
                    st.warning("DeÄŸerlendirilecek oturum verisi bulunamadÄ±.")
                else:
                    st.error("DeÄŸerlendirici servisi (Evaluator) baÅŸlatÄ±lamadÄ±.")

            # EÄŸer session_state'de bir sonuÃ§ varsa, onu gÃ¶ster
            if 'session_eval_result' in st.session_state:
                display_evaluation_results(st.session_state['session_eval_result'])
                
    else:
        st.error("VarsayÄ±lan veri yÃ¼klenemedi.") 