# Proje Teknik DokÃ¼mantasyonu

Bu belge, AI Agent DeÄŸerlendirme Sistemi'nin teknik yapÄ±sÄ±nÄ±, bileÅŸenlerini ve veri akÄ±ÅŸÄ±nÄ± aÃ§Ä±klamaktadÄ±r.

## 1. Genel BakÄ±ÅŸ

Projenin temel amacÄ±, yapay zeka ajanlarÄ±nÄ±n kullanÄ±cÄ±larla olan konuÅŸmalarÄ±nÄ± analiz ederek performanslarÄ±nÄ± belirli metrikler (Amaca Uygunluk, Persona TutarlÄ±lÄ±ÄŸÄ±, Bilgi SÄ±nÄ±rlarÄ± vb.) Ã§erÃ§evesinde deÄŸerlendirmektir. Sistem, kaydedilmiÅŸ konuÅŸma verilerini iÅŸler, bir deÄŸerlendirme modelinden geÃ§irir ve sonuÃ§larÄ± interaktif bir web arayÃ¼zÃ¼ Ã¼zerinden sunar.

Sistem Ã¼Ã§ ana bÃ¶lÃ¼mden oluÅŸur:
- **Veri Ä°ÅŸleme (ETL):** Ham veriyi (CSV) temizler ve vektÃ¶r veritabanÄ±na hazÄ±rlar.
- **DeÄŸerlendirme Motoru (Evaluation Engine):** LLM kullanarak konuÅŸmalarÄ± analiz eder ve puanlar.
- **Web ArayÃ¼zÃ¼ (Streamlit App):** DeÄŸerlendirme sÃ¼recini yÃ¶netmek ve sonuÃ§larÄ± gÃ¶rselleÅŸtirmek iÃ§in kullanÄ±lÄ±r.

## 2. Proje YapÄ±sÄ±

```
agent_recommendation_system_final/
â”‚
â”œâ”€â”€ api/                  # DeÄŸerlendirme servislerini dÄ±ÅŸarÄ±ya aÃ§an API (FastAPI).
â”‚   â””â”€â”€ main.py
â”‚
â”œâ”€â”€ chroma_db_openai/     # GÃ¶mme (embedding) vektÃ¶rlerinin saklandÄ±ÄŸÄ± veritabanÄ±.
â”‚
â”œâ”€â”€ etl/                  # Ham veriyi iÅŸleyen, temizleyen ve dÃ¶nÃ¼ÅŸtÃ¼ren script'ler.
â”‚   â”œâ”€â”€ data_processor.py
â”‚   â””â”€â”€ clean_data_processor.py
â”‚
â”œâ”€â”€ evaluation/           # DeÄŸerlendirme mantÄ±ÄŸÄ±nÄ± iÃ§eren Ã§ekirdek modÃ¼l.
â”‚   â””â”€â”€ evaluator.py
â”‚
â”œâ”€â”€ rag/                  # Retrieval-Augmented Generation (RAG) mantÄ±ÄŸÄ±nÄ± barÄ±ndÄ±rÄ±r.
â”‚   â””â”€â”€ rag_pipeline.py
â”‚
â”œâ”€â”€ vector_db/            # VektÃ¶r veritabanÄ± ve gÃ¶mme servisleri ile ilgili kodlar.
â”‚   â””â”€â”€ embedding_service.py
â”‚
â”œâ”€â”€ evaluation_app.py     # Streamlit ile oluÅŸturulmuÅŸ ana web uygulamasÄ±.
â”‚
â”œâ”€â”€ rebuild_database.py   # VeritabanÄ±nÄ± yeniden oluÅŸturan ana script.
â”‚
â””â”€â”€ requirements.txt      # Gerekli Python kÃ¼tÃ¼phaneleri.
```

## 3. Ana BileÅŸenlerin DetaylarÄ±

### a. `evaluation_app.py`
- **Teknoloji:** Streamlit
- **AmaÃ§:** Projenin kullanÄ±cÄ± arayÃ¼zÃ¼nÃ¼ oluÅŸturur. KullanÄ±cÄ±larÄ±n deÄŸerlendirme sÃ¼reÃ§lerini yÃ¶netmesini ve sonuÃ§larÄ± gÃ¶rmesini saÄŸlar.
- **Ä°ÅŸlevler:**
    - **Sandbox (Manuel DeÄŸerlendirme):** KullanÄ±cÄ±larÄ±n manuel olarak senaryo (kullanÄ±cÄ± sorusu, ajan cevabÄ±, persona, hedef) girmesine ve anÄ±nda deÄŸerlendirme sonuÃ§larÄ± almasÄ±na olanak tanÄ±r. Bu, hipotetik durumlarÄ± test etmek iÃ§in idealdir.
    - **Toplu DeÄŸerlendirme:** KullanÄ±cÄ±larÄ±n bir CSV dosyasÄ± yÃ¼kleyerek Ã§ok sayÄ±da konuÅŸmayÄ± tek seferde deÄŸerlendirmesini saÄŸlar. SonuÃ§lar, genel istatistikler ve detaylÄ± bir tablo olarak sunulur.
    - **Oturum DeÄŸerlendirme:** Veri setinden belirli bir konuÅŸma oturumunu seÃ§erek, baÅŸtan sona tÃ¼m diyaloÄŸu gÃ¶rÃ¼ntÃ¼leme ve bÃ¼tÃ¼nsel olarak deÄŸerlendirme imkanÄ± sunar.
- **Performans OptimizasyonlarÄ±:**
    - **KullanÄ±cÄ± Bekleme YÃ¶netimi:** LLM API Ã§aÄŸrÄ±larÄ± gibi zaman alan iÅŸlemler sÄ±rasÄ±nda arayÃ¼zÃ¼n donmasÄ±nÄ± engellemek ve kullanÄ±cÄ±ya sÃ¼recin devam ettiÄŸini bildirmek iÃ§in `st.spinner` ve `st.progress` gibi gÃ¶rsel bileÅŸenler kullanÄ±lÄ±r.
    - **Ã–nbellekleme (Caching):** `@st.cache_data` ve `@st.cache_resource` dekoratÃ¶rleri, bÃ¼yÃ¼k veri setlerinin (Ã¶rn: CSV dosyalarÄ±) ve servislerin (Ã¶rn: `AgentEvaluator`) tekrar tekrar yÃ¼klenmesini Ã¶nler. Veri ve servisler hafÄ±zada tutularak uygulama genelinde yÃ¼ksek performans saÄŸlanÄ±r.

### b. `evaluation/evaluator.py`
- **Teknoloji:** Pydantic, OpenAI API
- **AmaÃ§:** DeÄŸerlendirmenin beyin fonksiyonunu gÃ¶rÃ¼r. Bir konuÅŸmayÄ± veya oturumu alÄ±p, belirlenmiÅŸ metriklere gÃ¶re analiz eder.
- **Teknik Detaylar:**
    - `AgentEvaluator` sÄ±nÄ±fÄ±, `evaluate_conversation` ve `evaluate_session` metodlarÄ±nÄ± iÃ§erir.
    - Bu metodlar, OpenAI'nin `gpt-4` veya benzeri bir modeline Ã¶zel olarak hazÄ±rlanmÄ±ÅŸ bir "prompt" gÃ¶nderir. Bu prompt, konuÅŸma metnini, ajan hedefini, personasÄ±nÄ± ve deÄŸerlendirme kriterlerini iÃ§erir.
    - LLM'den gelen yanÄ±t, yapÄ±landÄ±rÄ±lmÄ±ÅŸ bir formatta (JSON) istenir ve `EvaluationMetrics` gibi Pydantic modelleri kullanÄ±larak parse edilir. Bu, sonuÃ§larÄ±n tutarlÄ± ve gÃ¼venilir olmasÄ±nÄ± saÄŸlar.

### c. `rag/rag_pipeline.py` & `vector_db/embedding_service.py`
- **Teknoloji:** ChromaDB, OpenAI Embeddings (`text-embedding-3-small`)
- **AmaÃ§:** Bu iki modÃ¼l, RAG sistemini oluÅŸturur.
- **Ä°ÅŸlevler:**
    - `embedding_service.py`: Metin verilerini (ajanÄ±n bilgi tabanÄ±) alÄ±r ve onlarÄ± sayÄ±sal vektÃ¶rlere (embeddings) dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r. Bu vektÃ¶rler, metnin anlamsal iÃ§eriÄŸini temsil eder.
    - `rag_pipeline.py`: Bir kullanÄ±cÄ± sorusu geldiÄŸinde, bu soruyu vektÃ¶re Ã§evirir ve ChromaDB'de en anlamsal olarak en yakÄ±n bilgi parÃ§acÄ±klarÄ±nÄ± (context) bulur. Bu bulunan baÄŸlam, ajanÄ±n daha doÄŸru ve temellendirilmiÅŸ cevaplar vermesi iÃ§in kullanÄ±lÄ±r.
    - **Not:** `evaluation_app` iÃ§inde RAG, doÄŸrudan bir baÄŸlam aramasÄ± yapmak yerine, ajanÄ±n verdiÄŸi cevabÄ±n "groundedness" (temellendirme) metriÄŸini Ã¶lÃ§mek iÃ§in simÃ¼le edilir.

### d. `etl/` & `rebuild_database.py`
- **AmaÃ§:** Ham veri kaynaklarÄ±nÄ± (CSV) iÅŸleyerek RAG sisteminin kullanabileceÄŸi temiz bir bilgi tabanÄ± oluÅŸturur.
- **Ä°ÅŸlevler:**
    - `data_processor.py`: CSV dosyalarÄ±nÄ± okur, birleÅŸtirir ve gerekli Ã¶n iÅŸlemleri yapar.
    - `rebuild_database.py`: ETL sÃ¼recini baÅŸlatan ana betiktir. `data_processor`'Ä± kullanarak veriyi alÄ±r, `embedding_service` ile vektÃ¶rlere dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r ve ChromaDB'ye kaydeder.

## 4. Veri AkÄ±ÅŸÄ±

AÅŸaÄŸÄ±daki ÅŸema, verinin sistemdeki yolculuÄŸunu Ã¶zetlemektedir:

```mermaid
graph TD
    subgraph "1. Veri HazÄ±rlama (ETL)"
        A[CSV DosyalarÄ±<br/>(KonuÅŸmalar, Personalar, GÃ¶revler)] --> B(ETL SÃ¼reÃ§leri<br/>`rebuild_database.py`);
        B --> C{VektÃ¶r VeritabanÄ±<br/>(ChromaDB)};
        D(GÃ¶mme Servisi<br/>`vector_db/embedding_service.py`) --> C;
    end

    subgraph "2. DeÄŸerlendirme UygulamasÄ± (Streamlit)"
        E[evaluation_app.py] --> F{DeÄŸerlendirme ArayÃ¼zÃ¼};
        A -- Ham KonuÅŸma Verisi --> H(DeÄŸerlendirici<br/>`evaluation/evaluator.py`);
        F -- KullanÄ±cÄ± Girdisi/SeÃ§imi --> H;
        H -- SonuÃ§larÄ± Hesaplar --> I[ğŸ“Š DeÄŸerlendirme SonuÃ§larÄ±];
        I --> F;
    end
```

1.  **ETL AÅŸamasÄ±:** `rebuild_database.py` Ã§alÄ±ÅŸtÄ±rÄ±ldÄ±ÄŸÄ±nda, CSV'lerdeki veriler iÅŸlenir, `embedding_service` kullanÄ±larak vektÃ¶rlere Ã§evrilir ve ChromaDB'ye yÃ¼klenir. Bu genellikle tek seferlik veya periyodik bir iÅŸlemdir.
2.  **DeÄŸerlendirme AÅŸamasÄ±:**
    - KullanÄ±cÄ± `evaluation_app.py` arayÃ¼zÃ¼nÃ¼ aÃ§ar.
    - Bir deÄŸerlendirme tÃ¼rÃ¼ seÃ§er (Sandbox, Toplu, Oturum).
    - Uygulama, ilgili konuÅŸma verilerini (CSV'den veya kullanÄ±cÄ± girdisinden) alÄ±r.
    - Bu veriler, `AgentEvaluator`'a gÃ¶nderilir.
    - `AgentEvaluator`, LLM'i kullanarak deÄŸerlendirmeyi yapar ve yapÄ±landÄ±rÄ±lmÄ±ÅŸ metrikleri (puan ve gerekÃ§e) dÃ¶ndÃ¼rÃ¼r.
    - SonuÃ§lar, arayÃ¼zde kullanÄ±cÄ±ya gÃ¶sterilir.

## 5. Kurulum ve GeliÅŸtirme

1.  **BaÄŸÄ±mlÄ±lÄ±klarÄ± YÃ¼kleme:**
    ```bash
    pip install -r requirements.txt
    ```

2.  **API AnahtarlarÄ±nÄ± Ayarlama:**
    Proje, OpenAI gibi servisler iÃ§in API anahtarlarÄ±na ihtiyaÃ§ duyar. Bu anahtarlarÄ± iÃ§eren bir `.env` dosyasÄ± oluÅŸturun (`env_example.txt` dosyasÄ±nÄ± kopyalayarak).
    ```
    OPENAI_API_KEY="sk-..."
    ```

3.  **VeritabanÄ±nÄ± OluÅŸturma (Ä°steÄŸe BaÄŸlÄ±):**
    EÄŸer bilgi tabanÄ±nÄ± yeniden oluÅŸturmak isterseniz:
    ```bash
    python rebuild_database.py
    ```

4.  **DeÄŸerlendirme UygulamasÄ±nÄ± Ã‡alÄ±ÅŸtÄ±rma:**
    ```bash
    streamlit run "agent_recommendation_system_final copy/evaluation_app.py"
    ``` 